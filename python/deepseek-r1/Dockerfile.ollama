# Use an Ubuntu base image
FROM ubuntu:22.04  
# Set environment variables to prevent interactive prompts
ENV DEBIAN_FRONTEND=noninteractive  
ENV OLLAMA_HOST=0.0.0.0:11435
# Install dependencies
RUN apt update && apt install -y curl  
# Install Ollama
RUN curl -fsSL https://ollama.com/install.sh | sh  
# Download and preload the Deepseek-r1 8B model
# Preload the Deepseek-r1 8B model by starting the service, pulling the model, then killing the service.
RUN bash -c ' \
    ollama serve & \
    pid=$!; \
    echo "Waiting for Ollama to start..."; \
    sleep 15; \
    echo "Pulling Deepseek-r1 8B model..."; \
    ollama pull deepseek-r1:8b; \
    kill $pid; \
    echo "Model pulled and service stopped." \
    '

# Expose the port for API access (optional)
EXPOSE 11435 

# Run Ollama as the default process
CMD ["ollama", "serve"]